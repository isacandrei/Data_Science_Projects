{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "def sum_common_words(common_words):\n",
    "    s=0\n",
    "    for w in common_words:\n",
    "        s=s+w[1]\n",
    "    return s\n",
    "\n",
    "def define_sentence_interest(common_words,sum_words_count,sents): #Define sentence interestingness\n",
    "    sent_interest=[0]*len(sents)\n",
    "    for idx,sent in enumerate(sents) :\n",
    "        for w in sent :\n",
    "            for cw in common_words:\n",
    "                if porter.stem(w.lower()) == cw[0]:   \n",
    "                    sent_interest[idx]+=cw[1]/sum_words_count #use the proportion as 'weight'\n",
    "    return sent_interest\n",
    "\n",
    "def key(item):\n",
    "    return item[2]\n",
    "\n",
    "def filter_sentences(threshold,sent_interest,sents): #Filter sentences based on their length and interestingness\n",
    "    interest_text=[]\n",
    "    for idx,s in enumerate(sent_interest):\n",
    "        if sent_interest[idx]>threshold and len(sents[idx])>4 and len(sents[idx])<max_sentence_length: #if 1/4 of the words in the sentece contain words from the most common words \n",
    "                                            #then consider this sentece as valuable\n",
    "            interest_text.append((idx,sents[idx],sent_interest[idx]))\n",
    "    return interest_text\n",
    "\n",
    "def generate_text(sorted_list): #Generate the summary \n",
    "    j=0\n",
    "    i=0\n",
    "    summary_text=''\n",
    "    while i < summary_words:\n",
    "        if j> len(sorted_list) : break\n",
    "        sentence=sorted_list[j][1]    \n",
    "        j+=1\n",
    "        summary_text+=\"\\n * \"\n",
    "        for w in sentence:\n",
    "            #print(w)\n",
    "            summary_text+=w+' '\n",
    "            i+=1;\n",
    "            if i>=summary_words : break\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "\n",
    "    sents = gutenberg.sents(text)\n",
    "    words = gutenberg.words(text)\n",
    "    distinct_words=set(words)\n",
    "    stop_words=stopwords.words('english')\n",
    "    filtered_words = [porter.stem(w.lower()) for w in words if w.lower() not in stop_words and len(w)>4]\n",
    " \n",
    "    fdist=nltk.FreqDist(filtered_words)\n",
    "    common_words=fdist.most_common(20);\n",
    "    sent_interest=[0]*len(sents)\n",
    "    sum_words_count=0\n",
    "    sum_words_count=sum_common_words(common_words) #use this in order to determine the 'weight'\n",
    "                                                    #of the word from the common words list\n",
    "                                                    #the higher number of occurences -> the bigger the 'weight'\n",
    "\n",
    "    sent_interest=define_sentence_interest(common_words,sum_words_count,sents)\n",
    "\n",
    "    threshold = sorted(common_words,reverse=False)[0][1]/sum_words_count\n",
    "    \n",
    "    interest_text=filter_sentences(threshold,sent_interest,sents)  \n",
    "\n",
    "    sorted_list=list(sorted(interest_text,key= key,reverse=True))\n",
    "    #print(len(sorted_list))\n",
    "    summary_text=generate_text(sorted_list)\n",
    "    print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = 'carroll-alice.txt' #input the fileid from the Gutenberg corpus\n",
    "\n",
    "summary_words=200\n",
    "max_sentence_length=50 #The maximum number of words in a sentence\n",
    "\n",
    "summarize(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "def sum_common_words(common_words):\n",
    "    s=0\n",
    "    for w in common_words:\n",
    "        s=s+w[1]\n",
    "    return s\n",
    "\n",
    "def define_sentence_interest(common_words,sum_words_count,sents): #Define sentence interestingness\n",
    "    sent_interest=[0]*len(sents)\n",
    "    for idx,sent in enumerate(sents) :\n",
    "        for w in sent :\n",
    "            for cw in common_words:\n",
    "                if porter.stem(w.lower()) == cw[0]:   \n",
    "                    sent_interest[idx]+=cw[1]/sum_words_count #use the proportion as 'weight'\n",
    "    return sent_interest\n",
    "\n",
    "def key(item):\n",
    "    return item[2]\n",
    "\n",
    "def getKey(item):\n",
    "    return item[0]\n",
    "\n",
    "def filter_sentences(threshold,sent_interest,sents): #Filter sentences based on their length and interestingness\n",
    "    interest_text=[]\n",
    "    for idx,s in enumerate(sent_interest):\n",
    "        if sent_interest[idx]>threshold and len(sents[idx])>4 and len(sents[idx])<max_sentence_length: #if 1/4 of the words in the sentece contain words from the most common words \n",
    "                                            #then consider this sentece as valuable\n",
    "            interest_text.append((idx,sents[idx],sent_interest[idx]))\n",
    "    return interest_text\n",
    "\n",
    "def generate_text(sorted_list): #Generate the summary \n",
    "    j=0\n",
    "    i=0\n",
    "    nsent=len(sorted_list);\n",
    "    \n",
    "    if nsent>30 : nsent=30;\n",
    "    \n",
    "    top_sentences=sorted_list[0:nsent]\n",
    "    l=list(sorted(top_sentences,key=getKey,reverse=False))\n",
    "    summary_text=''\n",
    "    while i < summary_words:\n",
    "        if j> len(l) : break\n",
    "        sentence=l[j][1]    \n",
    "        j+=1\n",
    "        if (i+len(sentence)>summary_words): break;\n",
    "        summary_text+=\"\\n * \"\n",
    "        for w in sentence:\n",
    "            #print(w)\n",
    "            summary_text+=w+' '\n",
    "            i+=1;\n",
    "            if i>=summary_words : break\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "\n",
    "    sents = gutenberg.sents(text)\n",
    "    words = gutenberg.words(text)\n",
    "    distinct_words=set(words)\n",
    "    stop_words=stopwords.words('english')\n",
    "    filtered_words = [porter.stem(w.lower()) for w in words if w.lower() not in stop_words and len(w)>4]\n",
    " \n",
    "    fdist=nltk.FreqDist(filtered_words)\n",
    "    common_words=fdist.most_common(20);\n",
    "    sent_interest=[0]*len(sents)\n",
    "    sum_words_count=0\n",
    "    sum_words_count=sum_common_words(common_words) #use this in order to determine the 'weight'\n",
    "                                                    #of the word from the common words list\n",
    "                                                    #the higher number of occurences -> the bigger the 'weight'\n",
    "\n",
    "    sent_interest=define_sentence_interest(common_words,sum_words_count,sents)\n",
    "\n",
    "    threshold = sorted(common_words,reverse=False)[0][1]/sum_words_count\n",
    "    \n",
    "    interest_text=filter_sentences(threshold,sent_interest,sents)  \n",
    "\n",
    "    sorted_list=list(sorted(interest_text,key= key,reverse=True))\n",
    "    #print(len(sorted_list))\n",
    "    summary_text=generate_text(sorted_list)\n",
    "    print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * For , you see , so many out - of - the - way things had happened lately , that Alice had begun to think that very few things indeed were really impossible . \n",
      " * ' Would it be of any use , now ,' thought Alice , ' to speak to this mouse ? \n",
      " * And she began fancying the sort of thing that would happen : '\" Miss Alice ! \n",
      " * Alice knew it was the Rabbit coming to look for her , and she trembled till she shook the house , quite forgetting that she was now about a thousand times as large as the Rabbit , and had no reason to be afraid of it . \n",
      " * thought Alice ; but she had not long to doubt , for the next moment a shower of little pebbles came rattling in at the window , and some of them hit her in the face . \n"
     ]
    }
   ],
   "source": [
    "text = 'carroll-alice.txt' #input the fileid from the Gutenberg corpus\n",
    "\n",
    "summary_words=200\n",
    "max_sentence_length=50 #The maximum number of words in a sentence\n",
    "\n",
    "summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

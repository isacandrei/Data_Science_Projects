{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"nltk_data\")\n",
    "from nltk.corpus import gutenberg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00104886  0.00061947  0.         ...,  0.          0.          0.00052443]\n",
      " [ 0.          0.00065283  0.00084064 ...,  0.00168129  0.00084064  0.        ]\n",
      " [ 0.          0.00042669  0.00054944 ...,  0.00109887  0.00054944  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#compute TD.IDF for 3 files\n",
    "\n",
    "texts = gutenberg.fileids()[:3]\n",
    "files = []\n",
    "for text in texts:\n",
    "    files.append(gutenberg.raw(text).replace('\\n', ' ').replace('_', ''))\n",
    "#     print(files[text])\n",
    "    \n",
    "vectorizer = TfidfVectorizer(stop_words='english',min_df=1)\n",
    "X = vectorizer.fit_transform(files)\n",
    "words = vectorizer.get_feature_names()\n",
    "# print (words) # print all the words\n",
    "# numpy.set_printoptions(threshold=numpy.nan)1 #use to view all X\n",
    "print (numpy.around(X.toarray(),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt\n",
      "mr  -  0.357436692024\n",
      "emma  -  0.344999193767\n",
      "harriet  -  0.265361890146\n",
      "weston  -  0.230749469692\n",
      "mrs  -  0.21712575486\n",
      "knightley  -  0.204003508432\n",
      "elton  -  0.202954647206\n",
      "miss  -  0.186461775215\n",
      "woodhouse  -  0.164671212462\n",
      "said  -  0.149912789376\n",
      "\n",
      "\n",
      "austen-persuasion.txt\n",
      "anne  -  0.324458969468\n",
      "elliot  -  0.319444893613\n",
      "captain  -  0.254715089464\n",
      "wentworth  -  0.240965352276\n",
      "mrs  -  0.189974970051\n",
      "charles  -  0.183487378338\n",
      "mr  -  0.167125746849\n",
      "russell  -  0.163591156591\n",
      "walter  -  0.155853737022\n",
      "musgrove  -  0.143694934843\n",
      "\n",
      "\n",
      "austen-sense.txt\n",
      "elinor  -  0.494873206804\n",
      "marianne  -  0.408902532921\n",
      "mrs  -  0.226143717665\n",
      "dashwood  -  0.182055544693\n",
      "said  -  0.169394445119\n",
      "jennings  -  0.166161806664\n",
      "willoughby  -  0.156047609737\n",
      "edward  -  0.144501733023\n",
      "lucy  -  0.134374330607\n",
      "sister  -  0.120325525248\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compute the most representative 10 words in 3 files\n",
    "i = 0\n",
    "for file in files:\n",
    "    # get array of word importance\n",
    "    importance = numpy.array(X.toarray()[i])\n",
    "    \n",
    "    # sort word importance\n",
    "    sorted_vals = numpy.argsort(importance)\n",
    "    reverse_sorted_vals = sorted_vals[::-1]\n",
    "    top_reverse_sorted_vals = reverse_sorted_vals[:10]\n",
    "    \n",
    "    #print results\n",
    "    print(texts[i])\n",
    "    for index in top_reverse_sorted_vals:\n",
    "        print (words[index], ' - ', importance[index])\n",
    "    print ('\\n')\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for where-was-that function, load corpus files\n",
    "texts = gutenberg.fileids()\n",
    "files = []\n",
    "for text in texts:\n",
    "    files.append(gutenberg.raw(text).replace('\\n', ' ').replace('_', ''))\n",
    "vectorizer = TfidfVectorizer(stop_words='english',min_df=1)\n",
    "\n",
    "#where-was-that function\n",
    "def find( str ):\n",
    "    files.append(str)\n",
    "    X = vectorizer.fit_transform(files)\n",
    "    # no need to normalize, since Vectorizer will return normalized tf-idf\n",
    "\n",
    "    #remove noise\n",
    "    X = numpy.around(X.toarray(),2)\n",
    "    # compute the dot croduct (cosine similarity)\n",
    "    pairwise_similarity = numpy.dot(X, numpy.transpose(X))\n",
    "    #choose only the required result (input file)\n",
    "    similarity = pairwise_similarity[len(files)-1][:len(files)-1]\n",
    "    \n",
    "    #sort the results\n",
    "    sorted_vals = numpy.argsort(similarity)\n",
    "    reverse_sorted_vals = sorted_vals[::-1]\n",
    "    top_reverse_sorted_vals = reverse_sorted_vals[:10]\n",
    "    \n",
    "    #check for obvious result\n",
    "    if similarity[top_reverse_sorted_vals[0]]/similarity[top_reverse_sorted_vals[1]] > 2:\n",
    "        print (\"The first result is the clear choice:\")\n",
    "    else:\n",
    "        print (\"There is no clear choice, but first is preffered:\")\n",
    "\n",
    "    #print results\n",
    "    i = 1\n",
    "    for index in top_reverse_sorted_vals:\n",
    "        print(i, \". \", texts[index], \" - \", similarity[index])\n",
    "        i +=1\n",
    "    \n",
    "    #remove input file in order to reuse files list\n",
    "    files.remove(str)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first result is the clear choice:\n",
      "1 .  melville-moby_dick.txt  -  0.3534\n",
      "2 .  bryant-stories.txt  -  0.024\n",
      "3 .  chesterton-brown.txt  -  0.0174\n",
      "4 .  whitman-leaves.txt  -  0.0066\n",
      "5 .  edgeworth-parents.txt  -  0.0036\n",
      "6 .  carroll-alice.txt  -  0.0036\n",
      "7 .  burgess-busterbrown.txt  -  0.0\n",
      "8 .  austen-persuasion.txt  -  0.0\n",
      "9 .  austen-sense.txt  -  0.0\n",
      "10 .  bible-kjv.txt  -  0.0\n",
      "\n",
      "\n",
      "There is no clear choice, but first is preffered:\n",
      "1 .  carroll-alice.txt  -  0.0476\n",
      "2 .  bryant-stories.txt  -  0.0397\n",
      "3 .  chesterton-brown.txt  -  0.0274\n",
      "4 .  burgess-busterbrown.txt  -  0.0126\n",
      "5 .  edgeworth-parents.txt  -  0.0121\n",
      "6 .  whitman-leaves.txt  -  0.0117\n",
      "7 .  blake-poems.txt  -  0.0086\n",
      "8 .  chesterton-ball.txt  -  0.0083\n",
      "9 .  melville-moby_dick.txt  -  0.0075\n",
      "10 .  chesterton-thursday.txt  -  0.0043\n",
      "\n",
      "\n",
      "The first result is the clear choice:\n",
      "1 .  carroll-alice.txt  -  0.5139\n",
      "2 .  bryant-stories.txt  -  0.0311\n",
      "3 .  chesterton-brown.txt  -  0.0212\n",
      "4 .  burgess-busterbrown.txt  -  0.01\n",
      "5 .  edgeworth-parents.txt  -  0.0093\n",
      "6 .  whitman-leaves.txt  -  0.0091\n",
      "7 .  blake-poems.txt  -  0.0066\n",
      "8 .  chesterton-ball.txt  -  0.0065\n",
      "9 .  melville-moby_dick.txt  -  0.0059\n",
      "10 .  chesterton-thursday.txt  -  0.0033\n",
      "\n",
      "\n",
      "There is no clear choice, but first is preffered:\n",
      "1 .  chesterton-brown.txt  -  0.1277\n",
      "2 .  whitman-leaves.txt  -  0.0972\n",
      "3 .  bryant-stories.txt  -  0.0899\n",
      "4 .  melville-moby_dick.txt  -  0.0851\n",
      "5 .  edgeworth-parents.txt  -  0.0811\n",
      "6 .  chesterton-thursday.txt  -  0.0716\n",
      "7 .  austen-persuasion.txt  -  0.0643\n",
      "8 .  chesterton-ball.txt  -  0.063\n",
      "9 .  milton-paradise.txt  -  0.0548\n",
      "10 .  austen-emma.txt  -  0.0473\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find(\"story with the sailor and the whale\")\n",
    "find(\"story with the girl falling into a rabbit hole\")\n",
    "find(\"story with the girl falling into a rabbit hole Alice\")\n",
    "find(\"man walk story now then ago time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
